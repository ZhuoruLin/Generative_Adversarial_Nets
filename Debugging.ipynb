{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "condition = torch.LongTensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = condition.cuda().size()\n",
    "size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./generate/generate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./generate/generate.py\n",
    "# %load ./generate/generate.py\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import pickle\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "embdict_url = 'https://s3.amazonaws.com/ds1008a3/embDict_cpu.pth'\n",
    "netG_url ='https://s3.amazonaws.com/ds1008a3/netG.pth'\n",
    "print('Downloading model files...')\n",
    "with urllib.request.urlopen(embdict_url) as response, open('embDict_cpu.pth', 'wb') as out_file:\n",
    "    data = response.read() \n",
    "    out_file.write(data)\n",
    "\n",
    "with urllib.request.urlopen(netG_url) as response, open('netG.pth', 'wb') as out_file:\n",
    "    data = response.read() \n",
    "    out_file.write(data)\n",
    "print('Download completed.')\n",
    "#Argument Parsing\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--emb_path',default='embDict_cpu.pth',type=str,help='Path to embedding (continue training)')\n",
    "parser.add_argument('--netG',default='netG.pth', help=\"path to netG (to continue training)\")\n",
    "\n",
    "opt = parser.parse_args()\n",
    "print(opt)\n",
    "\n",
    "#Necessary model definition\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "ngf=128\n",
    "nz=50\n",
    "emb_size=50\n",
    "nc=3\n",
    "  \n",
    "class _netG(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netG, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.inserted_dim = nz+emb_size\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     self.inserted_dim, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input,condition = None,embedding_dict = None):\n",
    "        emb = embedding_dict(condition)\n",
    "        catted_input = torch.cat([input,emb],1)\n",
    "        output = self.main(catted_input)\n",
    "        #if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "        #    output = nn.parallel.data_parallel(self.main, catted_input, range(self.ngpu))\n",
    "        #else:\n",
    "        #    output = self.main(catted_input)\n",
    "        return output\n",
    "\n",
    "ngpu=0\n",
    "nz=50\n",
    "netG = _netG(ngpu)\n",
    "netG.apply(weights_init)\n",
    "#Loading netG\n",
    "print('Loading netG')\n",
    "netG.load_state_dict(torch.load(opt.netG))\n",
    "print(netG)\n",
    "\n",
    "\n",
    "#Embedding Loading#\n",
    "print('Load embeddings...')\n",
    "class_embeddings = pickle.load(open(opt.emb_path,'rb'))\n",
    "#class_embeddings.cpu()\n",
    "num_classes = class_embeddings.num_embeddings\n",
    "emb_size = class_embeddings.embedding_dim\n",
    "#class_embeddings.cuda()\n",
    "print('Embedings dimension: %s | Number of classes: %s'%(emb_size,num_classes))\n",
    "print('-'*89)\n",
    "print()\n",
    "\n",
    "#Generate noise and conditions to plot######\n",
    "print('creating noise to plot')\n",
    "noise_to_plot = torch.FloatTensor(num_classes*13, nz, 1, 1).normal_(0,1)\n",
    "conditions_to_plot = np.arange(num_classes).repeat(13)\n",
    "conditions_to_plot = torch.from_numpy(conditions_to_plot)\n",
    "#noise_to_plot = noise_to_plot.cuda()\n",
    "#conditions_to_plot = conditions_to_plot.cuda()\n",
    "conditions_to_plot = Variable(conditions_to_plot)\n",
    "noise_to_plot = Variable(noise_to_plot)\n",
    "\n",
    "#printing\n",
    "print('generating output')\n",
    "fake = netG(noise_to_plot,conditions_to_plot,class_embeddings)\n",
    "vutils.save_image(fake.data,\n",
    "        'generated_samples.png',\n",
    "        normalize=True,nrow=13)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
